{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2114311,"sourceType":"datasetVersion","datasetId":1268506}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport spacy\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef load_legal_data(directory):\n    \"\"\"\n    Load legal text data from a directory.\n\n    Args:\n    - directory (str): Path to the directory containing legal text files.\n\n    Returns:\n    - texts (list): List of text content loaded from files in the directory.\n    \"\"\"\n    texts = []\n    for file_name in os.listdir(directory):\n        file_path = os.path.join(directory, file_name)\n        with open(file_path, 'r') as file:\n            content = file.read()\n            texts.append(content)\n    return texts\n\ndef preprocess_text(texts, nlp):\n    \"\"\"\n    Preprocess and vectorize text using SpaCy and TF-IDF.\n\n    Args:\n    - texts (list): List of text documents.\n    - nlp (spacy.Language): SpaCy language model.\n\n    Returns:\n    - tfidf_matrix (scipy.sparse.csr_matrix): TF-IDF matrix of vectorized text.\n    - vectorizer (sklearn.feature_extraction.text.TfidfVectorizer): TF-IDF vectorizer.\n    \"\"\"\n    processed_texts = [\" \".join([token.lemma_ for token in nlp(text) if not token.is_stop]) for text in texts]\n    vectorizer = TfidfVectorizer()\n    tfidf_matrix = vectorizer.fit_transform(processed_texts)\n    return tfidf_matrix, vectorizer\n\ndef get_most_relevant_text(query_vector, tfidf_matrix, texts):\n    \"\"\"\n    Retrieve the most relevant text based on cosine similarity.\n\n    Args:\n    - query_vector (scipy.sparse.csr_matrix): Vectorized query.\n    - tfidf_matrix (scipy.sparse.csr_matrix): TF-IDF matrix of vectorized text.\n    - texts (list): List of text documents.\n\n    Returns:\n    - most_relevant_text (str): Most relevant text document.\n    \"\"\"\n    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n    top_idx = similarities.argmax()\n    most_relevant_text = texts[top_idx]\n    return most_relevant_text\n\ndef main():\n    # Load legal data - Cases\n    cases_directory = '/kaggle/input/legalai/Object_casedocs/'\n    cases_texts = load_legal_data(cases_directory)\n\n    # Load legal data - Statutes\n    statutes_directory = '/kaggle/input/legalai/Object_statutes/'\n    statutes_texts = load_legal_data(statutes_directory)\n\n    # Load SpaCy language model\n    nlp = spacy.load(\"en_core_web_sm\")\n\n    # Preprocess and vectorize text for cases\n    tfidf_matrix_cases, vectorizer_cases = preprocess_text(cases_texts, nlp)\n\n    # Preprocess and vectorize text for statutes\n    tfidf_matrix_statutes, vectorizer_statutes = preprocess_text(statutes_texts, nlp)\n\n    # User interaction loop\n    while True:\n        user_query = input(\"Ask a legal-related question (type 'exit' to quit): \")\n\n        if user_query.lower() == 'exit':\n            print(\"Exiting the program. Goodbye!\")\n            break\n\n        # Vectorize user query\n        query_vector_cases = vectorizer_cases.transform([user_query])\n        query_vector_statutes = vectorizer_statutes.transform([user_query])\n\n        # Retrieve the most relevant case and statute\n        relevant_case = get_most_relevant_text(query_vector_cases, tfidf_matrix_cases, cases_texts)\n        relevant_statute = get_most_relevant_text(query_vector_statutes, tfidf_matrix_statutes, statutes_texts)\n\n        # Extract statutes from the relevant case\n        doc = nlp(relevant_case)\n        statutes = [ent.text for ent in doc.ents if ent.label_ == \"LAW\"]\n\n        # Summarize the relevant case\n        case_summary = \"\\n\".join([sent.text for sent in doc.sents])\n\n        # Generate Legal Document\n        legal_document = f\"Legal Document - User Query: {user_query}\\n\\n\"\n        legal_document += f\"Case Summary:\\n{case_summary}\\n\\n\"\n        legal_document += \"Relevant Statute:\\n\"\n        legal_document += f\"{relevant_statute}\\n\"\n        legal_document += \"\\nGuidance for the User:\\n\"\n        legal_document += \"To defend your friend in court, focus on presenting evidence that supports their actions were in self-defense.\\n\"\n        legal_document += \"Emphasize any mitigating circumstances and demonstrate their lack of intent to harm.\\n\"\n        legal_document += \"Consult with a qualified legal professional to build a strong defense strategy.\"\n\n        # Save or display the document to the user\n        with open(\"legal_document.txt\", \"w\") as output_file:\n            output_file.write(legal_document)\n\n        print(\"\\nLegal document created. You can find the document in 'legal_document.txt'.\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"_uuid":"80e922d4-c2b2-477f-bc98-defbafca57a4","_cell_guid":"faf4a680-8729-4aee-be8c-323a596785f9","execution":{"iopub.status.busy":"2024-04-16T08:12:23.441930Z","iopub.execute_input":"2024-04-16T08:12:23.443280Z","iopub.status.idle":"2024-04-16T08:52:44.265118Z","shell.execute_reply.started":"2024-04-16T08:12:23.443225Z","shell.execute_reply":"2024-04-16T08:52:44.263870Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdin","text":"Ask a legal-related question (type 'exit' to quit):  my friend did it accident how to help him\n"},{"name":"stdout","text":"\nLegal document created. You can find the document in 'legal_document.txt'.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Ask a legal-related question (type 'exit' to quit):  exit\n"},{"name":"stdout","text":"Exiting the program. Goodbye!\n","output_type":"stream"}]}]}